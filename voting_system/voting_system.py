# -*- coding: utf-8 -*-
"""Voting_system.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1QRXbIYvGu0PnPa79FXQuNEa7dXyWXT4K

导入一些用到的包
"""

import numpy as np
import matplotlib.pyplot as plt
import matplotlib.image as mpimg
import pandas as pd
import csv
import random
import math
from sklearn import preprocessing
from sklearn.model_selection import train_test_split

"""导入训练数据集（是CUHK还是OULAD）"""

# dataset = pd.read_csv('train_data1.csv')
dataset = pd.read_csv('train_data2.csv')
dataset.head()

"""选择X和y分别代表的对象（对于CUHK数据集选择1-6，OULAD数据集是1-9）"""

X = dataset.iloc[:,1:5].values
y = dataset['Level'].values

#X = dataset.iloc[:,1:9].values
#y = dataset.iloc[:,9].values

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)

"""KNN"""

import pickle
from sklearn.neighbors import KNeighborsClassifier
from sklearn import datasets
from sklearn.model_selection import train_test_split
import  matplotlib.pyplot as plt

knn=KNeighborsClassifier(n_neighbors=4)#选择邻近的2个点 #引入训练方法
knn.fit(X_train, y_train)

y_pred = knn.predict(X_test)
#print(y_pred)
y_pred2 = knn.predict(X)
#print(y_pred2)
df = pd.DataFrame(y_pred2)
df.to_csv('data.csv', index=False, header=False)
data=pd.read_csv(r'data.csv',header=None,names=['KNN'])
data.to_csv('predict_outcome.csv',index=False)

"""GBT"""

from sklearn.ensemble import GradientBoostingClassifier
clf = GradientBoostingClassifier(n_estimators=100, learning_rate=1.0, max_depth=1, random_state=0)
clf.fit(X_train,y_train)

y_pred = clf.predict(X_test)
y_pred2 = clf.predict(X)
df = pd.read_csv('predict_outcome.csv')
df['GBT'] = pd.DataFrame(y_pred2)
df.to_csv('predict_outcome.csv', index=False)

# df = pd.DataFrame(y_pred2)
# df.to_csv('data.csv', index=False, header=False)
# data=pd.read_csv(r'data.csv',header=None,names=['GBT'])
# data.to_csv('predict_outcome.csv',index=False)

"""NB"""

import pickle
from sklearn.naive_bayes import GaussianNB
nvclassifier = GaussianNB()
nvclassifier.fit(X_train, y_train)

y_pred = nvclassifier.predict(X_test)
y_pred2 = nvclassifier.predict(X)
df = pd.read_csv('predict_outcome.csv')
df['NB'] = pd.DataFrame(y_pred2)
df.to_csv('predict_outcome.csv', index=False)

"""SVC"""

from sklearn.svm import SVC
svcclassifier = SVC(kernel = 'linear', random_state = 0)
svcclassifier.fit(X_train, y_train)

y_pred = svcclassifier.predict(X_test)
y_pred2 = svcclassifier.predict(X)
df = pd.read_csv('predict_outcome.csv')
df['SVC'] = pd.DataFrame(y_pred2)
df.to_csv('predict_outcome.csv', index=False)

"""RF"""

from sklearn.ensemble import RandomForestClassifier
classifier = RandomForestClassifier( n_estimators = 200, criterion = 'entropy', random_state = 0)
classifier.fit(X_train,y_train)

# Predicting the Test set results
y_pred = classifier.predict(X_test)
y_pred2 = classifier.predict(X)
df = pd.read_csv('predict_outcome.csv')
df['RF'] = pd.DataFrame(y_pred2)
df.to_csv('predict_outcome.csv', index=False)

"""DT"""

from sklearn.tree import DecisionTreeClassifier
clf = DecisionTreeClassifier(random_state=0)
clf.fit(X_train,y_train)

# Predicting the Test set results
y_pred = clf.predict(X_test)
y_pred2 = clf.predict(X)
df = pd.read_csv('predict_outcome.csv')
df['DT'] = pd.DataFrame(y_pred2)
df.to_csv('predict_outcome.csv', index=False)

"""MLR"""

from sklearn.linear_model import LogisticRegression
logisticregression = LogisticRegression()
logisticregression.fit(X_train, y_train)
y_pred = logisticregression.predict(X_test)
y_pred2 = logisticregression.predict(X)

df = pd.read_csv('predict_outcome.csv')
df['MLR'] = pd.DataFrame(y_pred2)
df.to_csv('predict_outcome.csv', index=False)

"""增加权重"""

import pandas as pd

# 读取CSV文件
df = pd.read_csv('predict_outcome.csv')
# 各算法权重
""" w1 = 1 #KNN
w2 = 1 #GBT
w3 = 1 #NB
w4 = 1 #SVC
w5 = 1 #RF
w6 = 1 #DT
w7 = 1 #MLR """

# edited on 10 Mar 2024
'''weights=np.array([0.31,0.34,0.18,0.37,0.31,0.28,0.37])
exp_weights=np.exp(weights)
z=sum(exp_weights)
w1 = 7*exp_weights[0]/z #KNN
w2 = 7*exp_weights[1]/z #GBT
w3 = 7*exp_weights[2]/z #NB
w4 = 7*exp_weights[3]/z #SVC
w5 = 7*exp_weights[4]/z #RF
w6 = 7*exp_weights[5]/z #DT
w7 = 7*exp_weights[6]/z #MLR'''

#edited on 16 Mar 2024
""" from optimal_weights import Optimal
opt=Optimal()
weights=opt.optimal_weights """
weights=np.array([0.13709998,0.15023836,0.08733484,0.09536944,0.17764675,0.21932494,0.1329857])
w1=weights[0]
w2=weights[1]
w3=weights[2]
w4=weights[3]
w5=weights[4]
w6=weights[5]
w7=weights[6]

Weight_output = ['Prediction']
for i in range (0,len(df)):
  row_index = i  # 行索引
  element1 = 'A'
  element2 = 'B+'
  element3 = 'B'
  element4 = 'B-'
  element5 = 'C'
  element6 = 'D'
  element7 = 'F'

# 获取指定行的数据
  row_data = df.iloc[row_index]

  data = row_data.iloc[0] #读取KNN预测结果
  element_count1 = w1*data.count(element1) #A的次数
  element_count2 = w1*data.count(element2) #B+的次数
  element_count3 = w1*data.count(element3) #B的次数
  element_count4 = w1*data.count(element4) #B-的次数
  element_count5 = w1*data.count(element5) #C的次数
  element_count6 = w1*data.count(element6) #D的次数
  element_count7 = w1*data.count(element7) #F的次数

  data = row_data.iloc[1] #读取GBT预测结果
  element_count1 += w2*data.count(element1) #A的次数
  element_count2 += w2*data.count(element2) #B+的次数
  element_count3 += w2*data.count(element3) #B的次数
  element_count4 += w2*data.count(element4) #B-的次数
  element_count5 += w2*data.count(element5) #C的次数
  element_count6 += w2*data.count(element6) #D的次数
  element_count7 += w2*data.count(element7) #F的次数

  data = row_data.iloc[2] #读取NB预测结果
  element_count1 += w3*data.count(element1) #A的次数
  element_count2 += w3*data.count(element2) #B+的次数
  element_count3 += w3*data.count(element3) #B的次数
  element_count4 += w3*data.count(element4) #B-的次数
  element_count5 += w3*data.count(element5) #C的次数
  element_count6 += w3*data.count(element6) #D的次数
  element_count7 += w3*data.count(element7) #F的次数

  data = row_data.iloc[3] #读取SVC预测结果
  element_count1 += w4*data.count(element1) #A的次数
  element_count2 += w4*data.count(element2) #B+的次数
  element_count3 += w4*data.count(element3) #B的次数
  element_count4 += w4*data.count(element4) #B-的次数
  element_count5 += w4*data.count(element5) #C的次数
  element_count6 += w4*data.count(element6) #D的次数
  element_count7 += w4*data.count(element7) #F的次数

  data = row_data.iloc[4] #读取RF预测结果
  element_count1 += w5*data.count(element1) #A的次数
  element_count2 += w5*data.count(element2) #B+的次数
  element_count3 += w5*data.count(element3) #B的次数
  element_count4 += w5*data.count(element4) #B-的次数
  element_count5 += w5*data.count(element5) #C的次数
  element_count6 += w5*data.count(element6) #D的次数
  element_count7 += w5*data.count(element7) #F的次数

  data = row_data.iloc[5] #读取DT预测结果
  element_count1 += w6*data.count(element1) #A的次数
  element_count2 += w6*data.count(element2) #B+的次数
  element_count3 += w6*data.count(element3) #B的次数
  element_count4 += w6*data.count(element4) #B-的次数
  element_count5 += w6*data.count(element5) #C的次数
  element_count6 += w6*data.count(element6) #D的次数
  element_count7 += w6*data.count(element7) #F的次数

  data = row_data.iloc[6] #读取MLR预测结果
  element_count1 += w7*data.count(element1) #A的次数
  element_count2 += w7*data.count(element2) #B+的次数
  element_count3 += w7*data.count(element3) #B的次数
  element_count4 += w7*data.count(element4) #B-的次数
  element_count5 += w7*data.count(element5) #C的次数
  element_count6 += w7*data.count(element6) #D的次数
  element_count7 += w7*data.count(element7) #F的次数
#增加权重

  numbers = [element_count1, element_count2, element_count3, element_count4, element_count5, element_count6, element_count7]  # 假设这是你的数字列表
  labels = ['A', 'B+', 'B', 'B-', 'C', 'D', 'F']  # 假设这是与数字对应的标签列表

  max_number = max(numbers)  # 获取列表中的最大数
  max_index = numbers.index(max_number)  # 获取最大数的索引

  max_label = labels[max_index]  # 使用最大数的索引获取对应的标签

  Weight_output.append(max_label)

  #print(f"该学生出现最多的预测结果是{max_label}，该项投票得分是{max_number}")

data = Weight_output
filename = 'Weight_output.csv'  # 输出的CSV文件名
with open(filename, 'w', newline='') as csvfile:
    writer = csv.writer(csvfile)
    writer.writerow(data)

print(data)

#转置表格

input_file = 'Weight_output.csv'  # 输入的CSV文件名
output_file = 'Weight_output.csv'  # 输出的CSV文件名

# 读取输入CSV文件
with open(input_file, 'r') as csvfile:
    reader = csv.reader(csvfile)
    data = list(reader)

# 转置数据
transposed_data = list(map(list, zip(*data)))

# 写入转置后的数据到输出CSV文件
with open(output_file, 'w', newline='') as csvfile:
    writer = csv.writer(csvfile)
    writer.writerows(transposed_data)

df = pd.read_csv('True_level.csv')
column_data = df['Level']

df = pd.read_csv('Weight_output.csv')
df['True_level'] = column_data
df.to_csv('accuracy_comparison.csv', index=False)

"""比较仿真准确率"""

# 将之前的投票结果与学生成绩的真实值存在accuracy_comparison文件当中用以比较准确率
with open('accuracy_comparison.csv', 'r') as file:
    total = len(open('accuracy_comparison.csv').readlines())
    reader = csv.reader(file)
    # 跳过第一行
    next(reader)
    correct_number = 0
    # 遍历每一行并读取第一列的值
    for row in reader:
      if row[0] == row[1]:
        correct_number = correct_number+1
    print('Accuracy:', correct_number/total)